# Bayes_By_Example

What is this course about? I recently started a reinforcement learning project where the reward function of the RL learner was a bayesian model. Of course...I knew almost nothing about bayesian statistics before building out this RL learner! So, I spent a lot of time reading and trying to implement various online tutorials and research papers. This course is a collection of (mostly) other people's tutorials, but refactored to work together and provide a more holistic view of bayesian statistics than any one of these myriad of tutorials did originally. I've rewritten extensive portions of many of these tutorials and I apologize for any errors I may have accidentally introduced. I try to provide links or references to any and all resources I borrowed from to create this course in the sections where I reference said material.

All of the content is stored in Jupyter Notebooks. I recommend downloading the content locally. This will let you play with the code and actually run the examples for yourself. For best practices, I also recommend using a conda virtual environment to manage dependancies (take a look at the setup.sh file if you need help setting up your env and/or check out the [documentation](https://conda.io/docs/user-guide/tasks/manage-environments.html)).   

**Table of Contents:**

Part One:

* Who is this lecture for?
* What is statistics?
* The Frequentist Philosophy
* The Bayesian Philosophy
* Author's Note: Taking Sides

Part Two:

* Bayes: Conjugacy
* Bayes: Metropolis Hastings Sampling
* Bayes: My Friends Edward, Stan, and Pymc3

Part Three:

* Bayes: Hyper Priors
* Bayesians vs Frequentists (Student's T Test)
* <s>Bayesians vs Frequentists (A/B Testing)</s>
* <s>Bayes: Gibbs Sampling</s>

Part Four:

* Bayes: Linear Regression Part One (simple)
* Bayes: Linear Regression Part Two (regularization)
* Bayes: Linear Regression Part Three (robust)

Part Five:

* Bayes: Linear Regression Four (multi-level)
* Bayes: Linear Regression Four and Three Quarters (escaping the funnel)
* Samplers: Beyond Metropolis Hastings


Part Six:

* Bayes: Linear Regression with a Time Component (includes neural net with time component)

Part Seven:

* Bayes: Variational Inference

Part Eight:

* Bayes: Training Neural Nets Part One
* Bayes: Training Neural Nets Part Two
* Bayes: Training Neural Nets Part Three
* Bayes: Reguarization
* Bayes: Time Series Neural Nets

Part Nine:

* Mixture Models Part One
* Mixture Models Part Two
* Mixture Models Part Three
* Mixture Models Part Four

Part Ten:

* Gaussian Processes
* Parting Words

<s>Part Eleven:

* <s>Naive Bayes
